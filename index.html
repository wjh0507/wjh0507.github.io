<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>学无止境</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta property="og:type" content="website">
<meta property="og:title" content="学无止境">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="学无止境">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="学无止境" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<meta name="generator" content="Hexo 7.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">学无止境</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS Feed"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="Search"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main">
  
    <article id="post-JAVA多线程" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/08/18/JAVA%E5%A4%9A%E7%BA%BF%E7%A8%8B/" class="article-date">
  <time class="dt-published" datetime="2023-08-18T05:05:04.000Z" itemprop="datePublished">2023-08-18 13:05:04</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2023/08/18/JAVA%E5%A4%9A%E7%BA%BF%E7%A8%8B/">JAVA多线程</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h3 id="什么是线程？"><a href="#什么是线程？" class="headerlink" title="什么是线程？"></a>什么是线程？</h3><p>   线程是操作系统里执行逻辑运算的最小单位，它被进程包含在内，是进程中的实际运作单位。</p>
<h3 id="线程和进程有什么区别？"><a href="#线程和进程有什么区别？" class="headerlink" title="线程和进程有什么区别？"></a>线程和进程有什么区别？</h3><p>一个进程是一个独立(self contained)的运行环境，它可以被看作一个程序或者一个应用。而线程是在进程中执行的一个任务。</p>
<p>线程是进程的子集，一个进程可以有很多线程，每条线程并行执行不同的任务。</p>
<p>不同的进程使用不同的内存空间，而所有的线程共享一片相同的内存空间。</p>
<p>每个线程都拥有单独的栈内存用来存储本地数据。</p>
<h3 id="如何在Java中实现线程？"><a href="#如何在Java中实现线程？" class="headerlink" title="如何在Java中实现线程？"></a>如何在Java中实现线程？</h3><h4 id="（1）-继承Thread类实现多线程"><a href="#（1）-继承Thread类实现多线程" class="headerlink" title="（1）.继承Thread类实现多线程"></a>（1）.继承Thread类实现多线程</h4><p>继承Thread类,然后重写run方法.（由于Java单继承的特性，这种方式用的比较少）</p>
<pre><code>public class MyThread extends Thread &#123;
public MyThread() &#123;
    
&#125;
public void run() &#123;
    for(int i=0;i&lt;10;i++) &#123;
        System.out.println(Thread.currentThread()+&quot;:&quot;+i);
    &#125;
&#125;
public static void main(String[] args) &#123;
    MyThread mThread1=new MyThread();
    MyThread mThread2=new MyThread();
    MyThread myThread3=new MyThread();
    mThread1.start();
    mThread2.start();
    myThread3.start();
&#125;
&#125;
</code></pre>
<h4 id="（2）-实现Runnable-接口定制执行目标（target）类，实现其run-方法"><a href="#（2）-实现Runnable-接口定制执行目标（target）类，实现其run-方法" class="headerlink" title="（2）.实现Runnable()接口定制执行目标（target）类，实现其run()方法"></a>（2）.实现Runnable()接口定制执行目标（target）类，实现其run()方法</h4><p>推荐此方式。两个特点：</p>
<p> a.覆写Runnable接口实现多线程可以避免单继承局限<br> b.实现Runnable()可以更好的体现共享的概念<br> c.当执行目标类实现Runnable接口，此时执行目标（target）类和Thread是代理模式（子类负责真是业务的操作，thread负责资源调度与线程创建辅助真实业务。</p>
<pre><code>public class MyTarget implements Runnable&#123;
public static int count=20;
public void run() &#123;
    while(count&gt;0) &#123;
        try &#123;
            Thread.sleep(200);
        &#125; catch (InterruptedException e) &#123;
            e.printStackTrace();
        &#125;
        System.out.println(Thread.currentThread().getName()+&quot;-当前剩余票数:&quot;+count--);
    &#125;
&#125;
public static void main(String[] args) &#123;
    MyThread target=new MyTarget();
    Thread mThread1=new Thread(target,&quot;线程1&quot;);
    Thread mThread2=new Thread(target,&quot;线程2&quot;);
    Thread mThread3=new Thread(target,&quot;线程3&quot;);
    mThread1.start();
    mThread2.start();
    myThread3.start();
&#125;
&#125;
</code></pre>
<h4 id="（3）-通过线程池创建多线程"><a href="#（3）-通过线程池创建多线程" class="headerlink" title="（3）.通过线程池创建多线程"></a>（3）.通过线程池创建多线程</h4><p>JAVA中创建线程池主要有两类方法，一类是通过Executors工厂类提供的方法，该类提供了4种不同的线程池可供使用。另一类是通过ThreadPoolExecutor类进行自定义创建。<br>但是不建议使用 Executors静态工厂构建线程池（ <a target="_blank" rel="noopener" href="https://alibaba.github.io/p3c/%E7%BC%96%E7%A8%8B%E8%A7%84%E7%BA%A6/%E5%B9%B6%E5%8F%91%E5%A4%84%E7%90%86.html">此事在《阿里巴巴Java开发手册》里亦有记载</a>  </p>
<p>说明：Executors返回的线程池对象的弊端如下：<br>1：FixedThreadPool 和 SingleThreadPool：<br>允许的请求队列（底层实现是LinkedBlockingQueue）长度为Integer.MAX_VALUE，可能会堆积大量的请求，从而导致OOM<br>2：CachedThreadPool 和 ScheduledThreadPool 允许的创建线程数量为Integer.MAX_VALUE，可能会创建大量的线程，从而导致OOM。  </p>
<h5 id="一、通过ThreadPoolExecutor类自定义。"><a href="#一、通过ThreadPoolExecutor类自定义。" class="headerlink" title="一、通过ThreadPoolExecutor类自定义。"></a>一、通过ThreadPoolExecutor类自定义。</h5><p>　　ThreadPoolExecutor类提供了4种构造方法，可根据需要来自定义一个线程池。</p>
<pre><code>public ThreadPoolExecutor(int corePoolSize,
                          int maximumPoolSize,
                          long keepAliveTime,
                          TimeUnit unit,
                          BlockingQueue&lt;Runnable&gt; workQueue,
                          ThreadFactory threadFactory,
                          RejectedExecutionHandler handler) &#123;
    // 省略...
&#125;
</code></pre>
<p>1、共7个参数如下：</p>
<p>（1）corePoolSize：核心线程数，线程池中始终存活的线程数。<br>（2）maximumPoolSize: 最大线程数，线程池中允许的最大线程数。<br>（3）keepAliveTime: 存活时间，线程没有任务执行时最多保持多久时间会终止。<br>（4）unit: 单位，参数keepAliveTime的时间单位，7种可选。</p>
<table>
    <tr>
        <td>参数</td><td>描述</td>
    </tr>
    <tr>
        <td>TimeUnit.DAYS</td><td>天</td>
    </tr>
    <tr>
        <td>TimeUnit.HOURS</td><td>小时</td>
    </tr>
    <tr>
        <td>TimeUnit.MINUTES</td><td>分</td>
    </tr>
    <tr>
        <td>TimeUnit.SECONDS</td><td>秒</td>
    </tr>
    <tr>
        <td>TimeUnit.MILLISECONDS</td><td>毫秒</td>
    </tr>
    <tr>
        <td>TimeUnit.MICROSECONDS</td><td>微妙</td>
    </tr>
    <tr>
        <td>TimeUnit.NANOSECONDS</td><td>纳秒</td>
    </tr>
</table>

<p>（5）workQueue: 一个阻塞队列，用来存储等待执行的任务，均为线程安全，7种可选。  </p>
<table>
    <tr>
        <td>参数</td><td>描述</td>
    </tr>
    <tr>
        <td>ArrayBlockingQueue</td><td>一个由数组结构组成的有界阻塞队列</td>
    </tr>
    <tr>
        <td>LinkedBlockingQueue</td><td>一个由链表结构组成的有界阻塞队列</td>
    </tr>
    <tr>
        <td>SynchronousQueue</td><td>一个不存储元素的阻塞队列，即直接提交给线程不保持它们。</td>
    </tr>
    <tr>
        <td>PriorityBlockingQueue</td><td>一个支持优先级排序的无界阻塞队列</td>
    </tr>
    <tr>
        <td>DelayQueue</td><td>一个使用优先级队列实现的无界阻塞队列，只有在延迟期满时才能从中提取元素</td>
    </tr>
    <tr>
        <td>LinkedTransferQueue</td><td>一个由链表结构组成的无界阻塞队列。与SynchronousQueue类似，还含有非阻塞方法</td>
    </tr>
    <tr>
        <td>LinkedBlockingDeque</td><td>一个由链表结构组成的双向阻塞队列</td>
    </tr>
</table>

<p>较常用的是LinkedBlockingQueue和Synchronous。线程池的排队策略与BlockingQueue有关。</p>
<p>（6）threadFactory: 线程工厂，主要用来创建线程，默认为正常优先级、非守护线程。<br>（7）handler：拒绝策略，拒绝处理任务时的策略，4种可选，默认为AbortPolicy。<br>参数 	描述<br>AbortPolicy 	拒绝并抛出异常。<br>CallerRunsPolicy 	重试提交当前的任务，即再次调用运行该任务的execute()方法。<br>DiscardOldestPolicy 	抛弃队列头部（最旧）的一个任务，并执行当前任务。<br>DiscardPolicy 	抛弃当前任务。</p>
<p>2、顺便说下线程池的执行规则如下：</p>
<p>（1）当线程数小于核心线程数时，创建线程。</p>
<p>（2）当线程数大于等于核心线程数，且任务队列未满时，将任务放入任务队列。</p>
<p>（3）当线程数大于等于核心线程数，且任务队列已满：</p>
<p>若线程数小于最大线程数，创建线程。</p>
<p>若线程数等于最大线程数，抛出异常，拒绝任务。</p>
<pre><code>1     private static void createThreadPool() &#123;
2         ExecutorService executorService = new ThreadPoolExecutor(2, 10,
3                 1, TimeUnit.MINUTES, new ArrayBlockingQueue&lt;&gt;(5, true),
4                 Executors.defaultThreadFactory(), new ThreadPoolExecutor.AbortPolicy());
5         for (int i = 0; i &lt; 10; i++) &#123;
6             final int index = i;
7             executorService.execute(() -&gt; &#123;
8                 // 获取线程名称,默认格式:pool-1-thread-1
9                 System.out.println(DateUtil.now() + &quot; &quot; + Thread.currentThread().getName() + &quot; &quot; + index);
10                 // 等待2秒
11                 sleep(2000);
12             &#125;);
13         &#125;
14     &#125;
</code></pre>
<p>效果：  </p>
<pre><code>2023-08-21  18:05:30    pool-1-thread-3  7  
2023-08-21  18:05:30    pool-1-thread-4  8  
2023-08-21  18:05:30    pool-1-thread-2  1  
2023-08-21  18:05:30    pool-1-thread-1  0  
2023-08-21  18:05:30    pool-1-thread-5  9  
2023-08-21  18:05:32    pool-1-thread-3  2  
2023-08-21  18:05:32    pool-1-thread-4  3  
2023-08-21  18:05:32    pool-1-thread-2  4  
2023-08-21  18:05:32    pool-1-thread-1  5  
2023-08-21  18:05:32    pool-1-thread-5  6  
</code></pre>
<p>　　因为核心线程数为2，队列大小为5，存活时间1分钟，所以流程是第0-1号任务来时，陆续创建2个线程，然后第2-6号任务来时，因为无线程可用，均进入了队列等待，第7-9号任务来时，没有空闲线程，队列也满了，所以陆续又创建了3个线程。所以你会发现7-9号任务反而是先执行的。又因为各任务只需要2秒，而线程存活时间有1分钟，所以线程进行了复用，所以总共只创建了5个线程。</p>
<h5 id="二、通过Executors类提供的方法。"><a href="#二、通过Executors类提供的方法。" class="headerlink" title="二、通过Executors类提供的方法。"></a>二、通过Executors类提供的方法。</h5><h6 id="1-newCachedThreadPool"><a href="#1-newCachedThreadPool" class="headerlink" title="(1) newCachedThreadPool"></a>(1) newCachedThreadPool</h6><p>创建一个可缓存的线程池，若线程数超过处理所需，缓存一段时间后会回收，若线程数不够，则新建线程。</p>
<p>代码例子：</p>
<pre><code>1     private static void createCachedThreadPool() &#123;
2         ExecutorService executorService = Executors.newCachedThreadPool();
3         for (int i = 0; i &lt; 10; i++) &#123;
4             final int index = i;
5             executorService.execute(() -&gt; &#123;
6                 // 获取线程名称,默认格式:pool-1-thread-1
7                 System.out.println(DateUtil.now() + &quot; &quot; + Thread.currentThread().getName() + &quot; &quot; + index);
8                 // 等待2秒
9                 sleep(2000);
10             &#125;);
11         &#125;
12     &#125;
</code></pre>
<p>　　因为初始线程池没有线程，而线程不足会不断新建线程，所以线程名都是不一样的。</p>
<h6 id="2-newFixedThreadPool"><a href="#2-newFixedThreadPool" class="headerlink" title="(2) newFixedThreadPool"></a>(2) newFixedThreadPool</h6><p>创建一个固定大小的线程池，可控制并发的线程数，超出的线程会在队列中等待。<br>代码例子：</p>
<pre><code>1     private static void createFixedThreadPool() &#123;
2         ExecutorService executorService = Executors.newFixedThreadPool(3);
3         for (int i = 0; i &lt; 10; i++) &#123;
4             final int index = i;
5             executorService.execute(() -&gt; &#123;
6                 // 获取线程名称,默认格式:pool-1-thread-1
7                 System.out.println(DateUtil.now() + &quot; &quot; + Thread.currentThread().getName() + &quot; &quot; + index);
8                 // 等待2秒
9                 sleep(2000);
10             &#125;);
11         &#125;
12     &#125;  
</code></pre>
<p>　　因为线程池大小是固定的，这里设置的是3个线程，所以线程名只有3个。因为线程不足会进入队列等待线程空闲，所以日志间隔2秒输出。</p>
<h6 id="3-newScheduledThreadPool"><a href="#3-newScheduledThreadPool" class="headerlink" title="(3) newScheduledThreadPool"></a>(3) newScheduledThreadPool</h6><p>创建一个周期性的线程池，支持定时及周期性执行任务。</p>
<p>代码例子：</p>
<pre><code>1     private static void createScheduledThreadPool() &#123;
2         ScheduledExecutorService executorService = Executors.newScheduledThreadPool(3);
3         System.out.println(DateUtil.now() + &quot; 提交任务&quot;);
4         for (int i = 0; i &lt; 10; i++) &#123;
5             final int index = i;
6             executorService.schedule(() -&gt; &#123;
7                 // 获取线程名称,默认格式:pool-1-thread-1
8                 System.out.println(DateUtil.now() + &quot; &quot; + Thread.currentThread().getName() + &quot; &quot; + index);
9                 // 等待2秒
10                 sleep(2000);
11             &#125;, 3, TimeUnit.SECONDS);
12         &#125;
13     &#125;
</code></pre>
<p>　　因为设置了延迟3秒，所以提交后3秒才开始执行任务。因为这里设置核心线程数为3个，而线程不足会进入队列等待线程空闲，所以日志间隔2秒输出。</p>
<p>注意：这里用的是ScheduledExecutorService类的schedule()方法，不是ExecutorService类的execute()方法。</p>
<h6 id="4-newSingleThreadExecutor"><a href="#4-newSingleThreadExecutor" class="headerlink" title="(4) newSingleThreadExecutor"></a>(4) newSingleThreadExecutor</h6><p>创建一个单线程的线程池，可保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。</p>
<p>代码例子：</p>
<pre><code>1     private static void createSingleThreadPool() &#123;
2         ExecutorService executorService = Executors.newSingleThreadExecutor();
3         for (int i = 0; i &lt; 10; i++) &#123;
4             final int index = i;
5             executorService.execute(() -&gt; &#123;
6                 // 获取线程名称,默认格式:pool-1-thread-1
7                 System.out.println(DateUtil.now() + &quot; &quot; + Thread.currentThread().getName() + &quot; &quot; + index);
8                 // 等待2秒
9                 sleep(2000);
10             &#125;);
11         &#125;
12     &#125;
</code></pre>
<p>　　因为只有一个线程，所以线程名均相同，且是每隔2秒按顺序输出的。</p>
<h3 id="继承Thread类或者实现Runnable接口来创建线程，有何区别？"><a href="#继承Thread类或者实现Runnable接口来创建线程，有何区别？" class="headerlink" title="继承Thread类或者实现Runnable接口来创建线程，有何区别？"></a>继承Thread类或者实现Runnable接口来创建线程，有何区别？</h3><p>  Java不支持类的多重继承，但允许你调用多个接口。所以如果你要继承其他类，当然是调用Runnable接口好了。<br>  a.覆写Runnable接口实现多线程可以避免单继承局限<br>  b.实现Runnable()可以更好的体现共享的概念  </p>
<h3 id="Thread-类中的start-和-run-方法有什么区别？"><a href="#Thread-类中的start-和-run-方法有什么区别？" class="headerlink" title="Thread 类中的start() 和 run() 方法有什么区别？"></a>Thread 类中的start() 和 run() 方法有什么区别？</h3><p>start()方法被用来启动新创建的线程，使该被创建的线程状态变为可运行状态。<br>当你直接调用run()方法的时候，只会是在原来的线程中调用，没有新的线程启动。只有调用start()方法才会启动新线程。</p>
<p>如果我们调用了Thread的run()方法，它的行为就会和普通的方法一样，直接运行run（）方法。为了在新的线程中执行我们的代码，必须使用Thread.start()方法。</p>
<h3 id="Java中Runnable和Callable有什么不同？"><a href="#Java中Runnable和Callable有什么不同？" class="headerlink" title="Java中Runnable和Callable有什么不同？"></a>Java中Runnable和Callable有什么不同？</h3><p>Runnable和Callable都代表那些要在不同的线程中执行的任务目标target。</p>
<p>Runnable从JDK1.0开始就有了，Callable是在JDK1.5增加的。它们的主要区别是Callable的 call() 方法可以返回值和抛出异常，而Runnable的run()方法没有这些功能。  </p>
<h3 id="线程的常用方法有哪些"><a href="#线程的常用方法有哪些" class="headerlink" title="线程的常用方法有哪些"></a>线程的常用方法有哪些</h3><ul>
<li>Thread.sleep(long millis)，一定是当前线程调用此方法，当前线程进入TIMED_WAITING状态，但不释放对象锁，millis后线程自动苏醒进入就绪状态。作用：给其它线程执行机会的最佳方式。  </li>
<li>Thread.yield()，一定是当前线程调用此方法，当前线程放弃获取的CPU时间片，但不释放锁资源，由运行状态变为就绪状态，让OS再次选择线程。作用：让相同优先级的线程轮流执行，但并不保证一定会轮流执行。实际中无法保证yield()达到让步目的，因为让步的线程还有可能被线程调度程序再次选中。Thread.yield()不会导致阻塞。该方法与sleep()类似，只是不能由用户指定暂停多长时间。  </li>
<li>thread.join()&#x2F;thread.join(long millis)，当前线程里调用其它线程t的join方法，当前线程进入WAITING&#x2F;TIMED_WAITING状态，当前线程不会释放已经持有的对象锁。线程t执行完毕或者millis时间到，当前线程一般情况下进入RUNNABLE状态，也有可能进入BLOCKED状态（因为join是基于wait实现的）。  </li>
<li>obj.wait()，当前线程调用对象的wait()方法，当前线程释放对象锁，进入等待队列。依靠notify()&#x2F;notifyAll()唤醒或者wait(long timeout) timeout时间到自动唤醒。  </li>
<li>obj.notify()唤醒在此对象监视器上等待的单个线程，选择是任意性的。notifyAll()唤醒在此对象监视器上等待的所有线程。  </li>
<li>LockSupport.park()&#x2F;LockSupport.parkNanos(long nanos),LockSupport.parkUntil(long deadlines), 当前线程进入WAITING&#x2F;TIMED_WAITING状态。对比wait方法,不需要获得锁就可以让线程进入WAITING&#x2F;TIMED_WAITING状态，需要通过LockSupport.unpark(Thread thread)唤醒。</li>
</ul>
<h3 id="Java内存模型是什么？"><a href="#Java内存模型是什么？" class="headerlink" title="Java内存模型是什么？"></a>Java内存模型是什么？</h3><p>Java内存模型规定和指引Java程序在不同的内存架构、CPU和操作系统间有确定性地行为。它在多线程的情况下尤其重要。Java内存模型对一个线程所做的变动能被其它线程可见提供了保证，它们之间是先行发生关系。这个关系定义了一些规则让程序员在并发编程时思路更清晰。比如，先行发生关系确保了：</p>
<ul>
<li>线程内的代码能够按先后顺序执行，这被称为程序次序规则。</li>
<li>对于同一个锁，一个解锁操作一定要发生在时间上后发生的另一个锁定操作之前，也叫做管程锁定规则。</li>
<li>前一个对volatile的写操作在后一个volatile的读操作之前，也叫volatile变量规则。</li>
<li>一个线程内的任何操作必需在这个线程的start()调用之后，也叫作线程启动规则。</li>
<li>一个线程的所有操作都会在线程终止之前，线程终止规则。</li>
<li>一个对象的终结操作必需在这个对象构造完成之后，也叫对象终结规则。</li>
<li>可传递性</li>
</ul>
<h3 id="Java中的volatile-变量是什么？"><a href="#Java中的volatile-变量是什么？" class="headerlink" title="Java中的volatile 变量是什么？"></a>Java中的volatile 变量是什么？</h3><p>volatile是一个特殊的修饰符，只有成员变量才能使用它。在Java并发程序缺少同步类的情况下，多线程对成员变量的操作对其它线程是透明的。volatile变量可以保证下一个读取操作会在前一个写操作之后发生。线程都会直接从内存中读取该变量并且不缓存它。这就确保了线程读取到的变量是同内存中是一致的。</p>
<h3 id="什么是线程安全？Vector是一个线程安全类吗？"><a href="#什么是线程安全？Vector是一个线程安全类吗？" class="headerlink" title="什么是线程安全？Vector是一个线程安全类吗？"></a>什么是线程安全？Vector是一个线程安全类吗？</h3><p>如果你的代码所在的进程中有多个线程在同时运行，而这些线程可能会同时运行这段代码。如果每次运行结果和单线程运行的结果是一样的，而且其他的变量的值也和预期的是一样的，就是线程安全的。一个线程安全的计数器类的同一个实例对象在被多个线程使用的情况下也不会出现计算失误。很显然你可以将集合类分成两组，线程安全和非线程安全的。Vector 是用同步方法来实现线程安全的, 而和它相似的ArrayList不是线程安全的。</p>
<h3 id="Java中如何停止一个线程？"><a href="#Java中如何停止一个线程？" class="headerlink" title="Java中如何停止一个线程？"></a>Java中如何停止一个线程？</h3><p>Java提供了很丰富的API但没有为停止线程提供API。JDK 1.0本来有一些像stop(), suspend() 和 resume()的控制方法，但是由于潜在的死锁威胁。因此在后续的JDK版本中他们被弃用了，之后Java API的设计者就没有提供一个兼容且线程安全的方法来停止一个线程。当run() 或者 call() 方法执行完的时候线程会自动结束，如果要手动结束一个线程，可以用volatile 布尔变量来退出run()方法的循环或者是取消任务来中断线程。</p>
<h3 id="一个线程运行时发生异常会怎样？"><a href="#一个线程运行时发生异常会怎样？" class="headerlink" title="一个线程运行时发生异常会怎样？"></a>一个线程运行时发生异常会怎样？</h3><p>如果异常没有被捕获该线程将会停止执行。Thread.UncaughtExceptionHandler是用于处理未捕获异常造成线程突然中断情况的一个内嵌接口。  </p>
<p>当一个未捕获异常将造成线程中断的时候，JVM会使用Thread.getUncaughtExceptionHandler()来查询线程的UncaughtExceptionHandler并将线程和异常作为参数传递给handler的uncaughtException()方法进行处理。</p>
<h3 id="什么是FutureTask？"><a href="#什么是FutureTask？" class="headerlink" title="什么是FutureTask？###"></a>什么是FutureTask？###</h3><p>在Java并发程序中FutureTask表示一个可以取消的异步运算。它有启动和取消运算、查询运算是否完成和取回运算结果等方法。只有当运算完成的时候结果才能取回，如果运算尚未完成get方法将会阻塞。一个FutureTask对象可以对调用了Callable和Runnable的对象进行包装，由于FutureTask也是调用了Runnable接口所以它可以提交给Executor来执行。</p>
<h3 id="Java中堆和栈有什么不同？"><a href="#Java中堆和栈有什么不同？" class="headerlink" title="Java中堆和栈有什么不同？"></a>Java中堆和栈有什么不同？</h3><p>栈是一块和线程紧密相关的内存区域。每个线程都有自己的栈内存，用于存储本地变量，方法参数和栈调用，一个线程中存储的变量对其它线程是不可见的。而堆是所有线程共享的一片公用内存区域。对象都在堆里创建，为了提升效率线程会从堆中弄一个缓存到自己的栈，如果多个线程使用该变量就可能引发问题，这时volatile 变量就可以发挥作用了，它要求线程从主存中读取变量的值。</p>
<h3 id="如何避免死锁？"><a href="#如何避免死锁？" class="headerlink" title="如何避免死锁？"></a>如何避免死锁？</h3><p>Java多线程中的死锁</p>
<p>死锁是指两个或两个以上的进程在执行过程中，因争夺资源而造成的一种互相等待的现象，若无外力作用，它们都将无法推进下去。这是一个严重的问题，因为死锁会让你的程序挂起无法完成任务，死锁的发生必须满足以下四个条件：</p>
<ul>
<li>互斥条件：一个资源每次只能被一个进程使用。</li>
<li>请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。</li>
<li>不剥夺条件：进程已获得的资源，在末使用完之前，不能强行剥夺。</li>
<li>循环等待条件：若干进程之间形成一种头尾相接的循环等待资源关系。</li>
</ul>
<p>避免死锁最简单的方法就是阻止循环等待条件，将系统中所有的资源设置标志位、排序，规定所有的进程申请资源必须以一定的顺序（升序或降序）做操作来避免死锁。</p>
<h3 id="Java中活锁和死锁有什么区别？"><a href="#Java中活锁和死锁有什么区别？" class="headerlink" title="Java中活锁和死锁有什么区别？"></a>Java中活锁和死锁有什么区别？</h3><p>这是上题的扩展，活锁和死锁类似，不同之处在于处于活锁的线程或进程的状态是不断改变的，活锁可以认为是一种特殊的饥饿。一个现实的活锁例子是两个人在狭小的走廊碰到，两个人都试着避让对方好让彼此通过，但是因为避让的方向都一样导致最后谁都不能通过走廊。简单的说就是，活锁和死锁的主要区别是前者进程的状态可以改变但是却不能继续执行。</p>
<h3 id="什么是Callable和Future"><a href="#什么是Callable和Future" class="headerlink" title="什么是Callable和Future?"></a>什么是Callable和Future?</h3><p>Java 5在concurrency包中引入了java.util.concurrent.Callable 接口，它和Runnable接口很相似，但它可以返回一个对象或者抛出一个异常。</p>
<p>Callable接口使用泛型去定义它的返回类型。Executors类提供了一些有用的方法去在线程池中执行Callable内的任务。由于Callable任务是并行的，我们必须等待它返回的结果。java.util.concurrent.Future对象为我们解决了这个问题。在线程池提交Callable任务后返回了一个Future对象，使用它我们可以知道Callable任务的状态和得到Callable返回的执行结果。Future提供了get()方法让我们可以等待Callable结束并获取它的执行结果。</p>
<h3 id="什么是FutureTask"><a href="#什么是FutureTask" class="headerlink" title="什么是FutureTask?"></a>什么是FutureTask?</h3><p>FutureTask包装器是一种非常便利的机制，可将Callable转换成Future和Runnable，它同时实现两者的接口。</p>
<p>FutureTask类是Future 的一个实现，并实现了Runnable，所以可通过Excutor(线程池) 来执行。也可传递给Thread对象执行。如果在主线程中需要执行比较耗时的操作时，但又不想阻塞主线程时，可以把这些作业交给Future对象在后台完成，当主线程将来需要时，就可以通过Future对象获得后台作业的计算结果或者执行状态。</p>
<h3 id="有哪些不同的线程生命周期？"><a href="#有哪些不同的线程生命周期？" class="headerlink" title="有哪些不同的线程生命周期？"></a>有哪些不同的线程生命周期？</h3><p>当我们在Java程序中新建一个线程时，它的状态是New。当我们调用线程的start()方法时，状态被改变为Runnable。线程调度器会为Runnable线程池中的线程分配CPU时间并且讲它们的状态改变为Running。其他的线程状态还有Waiting，Blocked 和Dead。</p>
<h3 id="线程之间是如何通信的？"><a href="#线程之间是如何通信的？" class="headerlink" title="线程之间是如何通信的？"></a>线程之间是如何通信的？</h3><p>当线程间是可以共享资源时，线程间通信是协调它们的重要的手段。Object类中wait()\notify()\notifyAll()方法可以用于线程间通信关于资源的锁的状态。</p>
<h3 id="如何确保线程安全？"><a href="#如何确保线程安全？" class="headerlink" title="如何确保线程安全？"></a>如何确保线程安全？</h3><p>在Java中可以有很多方法来保证线程安全——</p>
<ul>
<li>同步，</li>
<li>使用原子类(atomic concurrent classes)，  </li>
<li>使用显示锁，</li>
<li>使用volatile关键字，</li>
<li>使用不变类</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2023/08/18/JAVA%E5%A4%9A%E7%BA%BF%E7%A8%8B/" data-id="cm1j2utfd0000b8uk9yh07qyw" data-title="JAVA多线程" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-Kafka相关命令" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2022/08/11/Kafka%E7%9B%B8%E5%85%B3%E5%91%BD%E4%BB%A4/" class="article-date">
  <time class="dt-published" datetime="2022-08-10T23:53:58.000Z" itemprop="datePublished">2022-08-11 07:53:58</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2022/08/11/Kafka%E7%9B%B8%E5%85%B3%E5%91%BD%E4%BB%A4/">Kafka相关命令</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="Kafka基础命令"><a href="#Kafka基础命令" class="headerlink" title="Kafka基础命令"></a>Kafka基础命令</h2><p>说明：命令行参数中–zookeeper是2.2以前的版本，2.2之后使用–bootstrap-server</p>
<h3 id="检查端口号"><a href="#检查端口号" class="headerlink" title="检查端口号"></a>检查端口号</h3><pre><code>ps -ef | grep kafka 
netstat -tunlp|grep &quot;(2181|9092)&quot;
</code></pre>
<h2 id="topic相关"><a href="#topic相关" class="headerlink" title="topic相关"></a>topic相关</h2><h3 id="创建"><a href="#创建" class="headerlink" title="创建"></a>创建</h3><pre><code>bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 3 --topic TEST_TOPIC
</code></pre>
<h3 id="查看topic列表"><a href="#查看topic列表" class="headerlink" title="查看topic列表"></a>查看topic列表</h3><pre><code>bin/kafka-topics.sh --list --bootstrap-server localhost:9092
</code></pre>
<p>除了手动创建topic，还可以配置auto.create.topics.enable 参数(默认为true)，当一个不存在的topic发布时可自动创建,但分区和副本默认值为1，可通过修改num.partitions和default.replication.factor参数来修改</p>
<p>上述有的版本bootstrap-server要改成zookeeper 2181用</p>
<h3 id="查看某个topic信息"><a href="#查看某个topic信息" class="headerlink" title="查看某个topic信息"></a>查看某个topic信息</h3><pre><code>bin/kafka-topics.sh --describe --bootstrap-server localhost:9092 --topic TEST_TOPIC
</code></pre>
<h3 id="修改某个topic的partition个数-分区只能增不能减"><a href="#修改某个topic的partition个数-分区只能增不能减" class="headerlink" title="修改某个topic的partition个数(分区只能增不能减)"></a>修改某个topic的partition个数(分区只能增不能减)</h3><blockquote>
<p>bin&#x2F;kafka-topics.sh –bootstrap-server localhost:2181 –alter –topic TEST_TOPIC –partitions 10</p>
</blockquote>
<h3 id="删除某个topic-只会删除zookeeper内的元数据，消息文件需要手动删除"><a href="#删除某个topic-只会删除zookeeper内的元数据，消息文件需要手动删除" class="headerlink" title="删除某个topic(只会删除zookeeper内的元数据，消息文件需要手动删除)"></a>删除某个topic(只会删除zookeeper内的元数据，消息文件需要手动删除)</h3><p>如果启动时server.properties没有配置delete.topic.enable&#x3D;true，此时删除只是把topic标记为：marked for deletion，日志数据（log.dirs配置的位置）并未删除</p>
<pre><code> bin/kafka-topics.sh --bootstrap-server localhost:2181  --topic TEST_TOPIC --delete
</code></pre>
<h2 id="producer相关"><a href="#producer相关" class="headerlink" title="producer相关"></a>producer相关</h2><p>一般用来做测试，命令行和文件都支持</p>
<pre><code>bin/kafka-console-producer --broker-list localhost:9092 --topic test
&gt;我是一条测试消息
</code></pre>
<p>预研测试的时候经常读文件更方便：</p>
<pre><code>cat data001.txt |  kafka-console-producer --broker-list localhost:9092 --topic test_data001 | &gt; out001.txt
</code></pre>
<p>附：wc -l data.txt查看文件行数</p>
<h2 id="consumer相关"><a href="#consumer相关" class="headerlink" title="consumer相关"></a>consumer相关</h2><h3 id="查看所有消费者组"><a href="#查看所有消费者组" class="headerlink" title="查看所有消费者组"></a>查看所有消费者组</h3><pre><code> bin/kafka-consumer-groups --bootstrap-server localhost:9092 --list
</code></pre>
<h3 id="查看指定group（group01）的消费情况"><a href="#查看指定group（group01）的消费情况" class="headerlink" title="查看指定group（group01）的消费情况"></a>查看指定group（group01）的消费情况</h3><pre><code> bin/kafka-consumer-groups --describe --group group01 --bootstrap-server localhost:9092
</code></pre>
<h2 id="console相关"><a href="#console相关" class="headerlink" title="console相关"></a>console相关</h2><h3 id="生产数据"><a href="#生产数据" class="headerlink" title="生产数据"></a>生产数据</h3><pre><code> bin/kafka-console-producer --broker-list localhost:9092 --topic TEST_TOPIC
</code></pre>
<h3 id="消费数据"><a href="#消费数据" class="headerlink" title="消费数据"></a>消费数据</h3><pre><code> bin/kafka-console-consumer --bootstrap-server localhost:9092 --from-beginning --topic TEST_TOPIC
</code></pre>
<h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><h3 id="重置指定topic的offset"><a href="#重置指定topic的offset" class="headerlink" title="重置指定topic的offset"></a>重置指定topic的offset</h3><p>新闻数据有脏数据导致Kafka Connect执行错误，需要跳过脏数据</p>
<pre><code> bin/kafka-consumer-groups --bootstrap-server localhost:9092 --group group_test --reset-offsets -to-offset 97000000 --topic TEST_TOPIC --execute

Other supported arguments:
--shift-by [positive or negative integer] - Shifts offset forward or backward from given integer.往前或往后加减offset
--to-current and --to-latest are same as --to-offset [integer] and --to-earliest.
--to-datetime [Datetime format is yyyy-MM-ddTHH:mm:ss.xxx]
 bin/kafka-consumer-groups --bootstrap-server localhost:9092 --group group_test --reset-offsets --to-datetime 2017-08-04T00:00:00.000 [ --all-topics or --topic &lt;topic-name&gt; ] --execute
</code></pre>
<p>how to validata:</p>
<pre><code> bin/kafka-consumer-groups --bootstrap-server locahost:9092 --group &lt;group_id&gt; --describe
</code></pre>
<p>注意：这里重置的offset是针对每个partition而言，重置offset之前，所有的consumer必须是inactive的，也就是应用消费必须暂停</p>
<h2 id="Kafka查看topic、consumer-group状态命令"><a href="#Kafka查看topic、consumer-group状态命令" class="headerlink" title="Kafka查看topic、consumer group状态命令"></a>Kafka查看topic、consumer group状态命令</h2><p>最近工作中遇到需要使用kafka的场景，测试消费程序启动后，要莫名的过几十秒乃至几分钟才能成功获取到到topic的partition和offset，而后开始消费数据，于是学习了一下查看kafka broker里topic和consumer group状态的相关命令，这里记录一下。</p>
<p>以下命令中使用的zookeeper配置地址为127.0.0.1:2181，bootstrap–server(即broker)地址为: 127.0.0.1:9292</p>
<h3 id="查看kafka-topic列表，使用–list参数"><a href="#查看kafka-topic列表，使用–list参数" class="headerlink" title="查看kafka topic列表，使用–list参数"></a>查看kafka topic列表，使用–list参数</h3><pre><code>bin/kafka-topics.sh --zookeeper 127.0.0.1:2181 --list
__consumer_offsets
test_topic
test
</code></pre>
<h3 id="查看kafka特定topic的详情，使用–topic与–describe参数"><a href="#查看kafka特定topic的详情，使用–topic与–describe参数" class="headerlink" title="查看kafka特定topic的详情，使用–topic与–describe参数"></a>查看kafka特定topic的详情，使用–topic与–describe参数</h3><pre><code>bin/kafka-topics.sh --zookeeper 127.0.0.1:2181 --topic test_topic --describe
Topic:test_topic    PartitionCount:1        ReplicationFactor:1     Configs:
Topic:test_topic    Partition: 0    Leader: 0       Replicas: 0     Isr: 0
</code></pre>
<p>列出了test_topic的parition数量、replica因子以及每个partition的leader、replica信息</p>
<h3 id="查看consumer-group列表，使用–list参数"><a href="#查看consumer-group列表，使用–list参数" class="headerlink" title="查看consumer group列表，使用–list参数"></a>查看consumer group列表，使用–list参数</h3><p>查看consumer group列表有新、旧两种命令，分别查看新版(信息保存在broker中)consumer列表和老版(信息保存在zookeeper中)consumer列表，因而需要区分指定bootstrap–server和zookeeper参数：</p>
<pre><code>bin/kafka-consumer-groups.sh --new-consumer --bootstrap-server 127.0.0.1:9292 --list
lx_test

bin/kafka-consumer-groups.sh --zookeeper 127.0.0.1:2181 --list
console-consumer-86845
console-consumer-11967
</code></pre>
<h3 id="查看特定consumer-group-详情，使用–group与–describe参数"><a href="#查看特定consumer-group-详情，使用–group与–describe参数" class="headerlink" title="查看特定consumer group 详情，使用–group与–describe参数"></a>查看特定consumer group 详情，使用–group与–describe参数</h3><p>同样根据新&#x2F;旧版本的consumer，分别指定bootstrap-server与zookeeper参数:</p>
<pre><code>bin/kafka-consumer-groups.sh --new-consumer --bootstrap-server 127.0.0.1:9292 --group lx_test --describe
bin/kafka-consumer-groups.sh --zookeeper 127.0.0.1:2181 --group console-consumer-11967 --describe
GROUP                          TOPIC                          PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             OWNER
Could not fetch offset from zookeeper for group console-consumer-11967 partition [test_topic,0] due to missing offset data in zookeeper.
console-consumer-11967         test_topic             0          unknown         465             unknown         console-consumer-11967_aws-lx-1513787888172-d3a91f05-0
</code></pre>
<p>其中依次展示group名称、消费的topic名称、partition id、consumer group最后一次提交的offset、最后提交的生产消息offset、消费offset与生产offset之间的差值、当前消费topic-partition的group成员id(不一定包含hostname)</p>
<p>上面示例中console-consumer-11967是为了测试临时起的一个console consumer，缺少在zookeeper中保存的current_offset信息。</p>
<h2 id="设置为最初偏移量："><a href="#设置为最初偏移量：" class="headerlink" title="设置为最初偏移量："></a>设置为最初偏移量：</h2><pre><code>./kafka-consumer-groups.sh --bootstrap-server snn:6667 --group offsettest --topic offset-test --reset-offsets --to-earliest –execute
</code></pre>
<h2 id="设置任意偏移量："><a href="#设置任意偏移量：" class="headerlink" title="设置任意偏移量："></a>设置任意偏移量：</h2><pre><code>./kafka-consumer-groups.sh --bootstrap-server snn:6667 --group offsettest --topic offset-test --reset-offsets --to-offset 3 –execute
</code></pre>
<h2 id="设置最近偏移量"><a href="#设置最近偏移量" class="headerlink" title="设置最近偏移量"></a>设置最近偏移量</h2><pre><code>./kafka-consumer-groups.sh --bootstrap-server snn:6667 --group offsettest --topic offset-test --reset-offsets --to-latest --execute
</code></pre>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2022/08/11/Kafka%E7%9B%B8%E5%85%B3%E5%91%BD%E4%BB%A4/" data-id="cm1j2utfh0002b8ukc8vb8ten" data-title="Kafka相关命令" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-kafka自动创建Topic设置" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2022/08/10/kafka%E8%87%AA%E5%8A%A8%E5%88%9B%E5%BB%BATopic%E8%AE%BE%E7%BD%AE/" class="article-date">
  <time class="dt-published" datetime="2022-08-10T15:50:41.000Z" itemprop="datePublished">2022-08-10 23:50:41</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2022/08/10/kafka%E8%87%AA%E5%8A%A8%E5%88%9B%E5%BB%BATopic%E8%AE%BE%E7%BD%AE/">Partitions与Replication Factor调整准则</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>Partition 数目与Replication Factor是在创建一个topic时非常重要的两个参数，这两个参数的取值会直接影响到系统的性能与稳定性。</p>
<p>尽量在第一次创建一个topic时就指定这两个参数，因为</p>
<pre><code>如果Partition 数目在之后再次做调整，则会打乱key的顺序保证（同样的key会分布到不同的partition上）
如果Replication Factor在之后再次增加，则会给集群带来更大的压力，可能会导致性能下降
</code></pre>
<ol>
<li>Partition 数目</li>
</ol>
<p>一般来说，每个partition 能处理的吞吐为几MB&#x2F;s（仍需要基于根据本地环境测试后获取准确指标），增加更多的partitions意味着：</p>
<pre><code>更高的并行度与吞吐
可以扩展更多的（同一个consumer group中的）consumers
若是集群中有较多的brokers，则可更大程度上利用闲置的brokers
但是会造成Zookeeper的更多选举
也会在Kafka中打开更多的文件
</code></pre>
<p>调整准则：</p>
<pre><code>一般来说，若是集群较小（小于6个brokers），则配置2 x broker数的partition数。在这里主要考虑的是之后的扩展。若是集群扩展了一倍（例如12个），则不用担心会有partition不足的现象发生
一般来说，若是集群较大（大于12个），则配置1 x broker 数的partition数。因为这里不需要再考虑集群的扩展情况，与broker数相同的partition数已经足够应付常规场景。若有必要，则再手动调整
考虑最高峰吞吐需要的并行consumer数，调整partition的数目。若是应用场景需要有20个（同一个consumer group中的）consumer并行消费，则据此设置为20个partition
考虑producer所需的吞吐，调整partition数目（如果producer的吞吐非常高，或是在接下来两年内都比较高，则增加partition的数目）
</code></pre>
<p>以上仅是几个基本准则，最重要的是：在本地集群做测试，以获取一个更合适的partition数目，不同的集群会有不同的性能。</p>
<ol start="2">
<li>Replication factor</li>
</ol>
<p>此参数决定的是records复制的数目，建议至少 设置为2，一般是3，最高设置为4。更高的replication factor（假设数目为N）意味着：</p>
<pre><code>系统更稳定（允许N-1个broker宕机）
更多的副本（如果acks=all，则会造成较高的延时）
系统磁盘的使用率会更高（一般若是RF为3，则相对于RF为2时，会占据更多50% 的磁盘空间）
</code></pre>
<p>调整准则：</p>
<pre><code>以3为起始（当然至少需要有3个brokers，同时也不建议一个Kafka 集群中节点数少于3个节点）
如果replication 性能成为了瓶颈或是一个issue，则建议使用一个性能更好的broker，而不是降低RF的数目
永远不要在生产环境中设置RF为1
</code></pre>
<ol start="3">
<li>集群调整建议</li>
</ol>
<p>一个已被业界接受的准则是：</p>
<pre><code>一个broker不应该承载超过2000 到 4000 个partitions（考虑此broker上所有来自不同topics的partitions）。同时，一个Kafka集群上brokers中所有的partitions总数最多不应超过20,000个。
</code></pre>
<p>此准则基于的原理是：在有broker宕机后，zookeeper需要重新做选举。若是partitions数目过多，则需要执行大量的leader elections。</p>
<p>另外几个常规原则有：</p>
<pre><code>如果集群中需要更多的partitions，则优先考虑增加brokers
如果集群中需要20,000 个以上的partitions，则可以参考Netflix的模型，创建更多的Kafka 集群
</code></pre>
<p>最后需要注意的是：不要为一个topic创建超过1000个的partitions。我们也并不需要1000个partitions才能达到很高的吞吐。在开始的时候，选择一个更合理的partition数目，然后测试性能，根据测试结果再调整partitions 数目。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2022/08/10/kafka%E8%87%AA%E5%8A%A8%E5%88%9B%E5%BB%BATopic%E8%AE%BE%E7%BD%AE/" data-id="cm1j2utfi0004b8uke7g8bsk7" data-title="Partitions与Replication Factor调整准则" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-Spark面对OOM问题的解决方法及优化总结" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/06/11/Spark%E9%9D%A2%E5%AF%B9OOM%E9%97%AE%E9%A2%98%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95%E5%8F%8A%E4%BC%98%E5%8C%96%E6%80%BB%E7%BB%93/" class="article-date">
  <time class="dt-published" datetime="2021-06-11T08:33:44.000Z" itemprop="datePublished">2021-06-11 16:33:44</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2021/06/11/Spark%E9%9D%A2%E5%AF%B9OOM%E9%97%AE%E9%A2%98%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95%E5%8F%8A%E4%BC%98%E5%8C%96%E6%80%BB%E7%BB%93/">Spark面对OOM问题的解决方法及优化总结</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h3 id="Spark中的OOM问题不外乎以下两种情况"><a href="#Spark中的OOM问题不外乎以下两种情况" class="headerlink" title="Spark中的OOM问题不外乎以下两种情况"></a>Spark中的OOM问题不外乎以下两种情况</h3><ul>
<li><p>map执行中内存溢出</p>
</li>
<li><p>shuffle后内存溢出</p>
<p>  map执行中内存溢出代表了所有map类型的操作，包括：flatMap，filter，mapPatitions等。shuffle后内存溢出的shuffle操作包括join，reduceByKey，repartition等操作。后面先总结一下我对Spark内存模型的理解，再总结各种OOM的情况相对应的解决办法和性能优化方面的总结。如果理解有错，希望在评论中指出。</p>
</li>
</ul>
<h3 id="Spark-内存模型："><a href="#Spark-内存模型：" class="headerlink" title="Spark 内存模型："></a>Spark 内存模型：</h3><p>Spark在一个Executor中的内存分为三块，一块是execution内存，一块是storage内存，一块是other内存。</p>
<ul>
<li>execution内存是执行内存，文档中说join，aggregate都在这部分内存中执行，shuffle的数据也会先缓存在这个内存中，满了再写入磁盘，能够减少IO。其实map过程也是在这个内存中执行的。</li>
<li>storage内存是存储broadcast，cache，persist数据的地方。</li>
<li>other内存是程序执行时预留给自己的内存。</li>
</ul>
<p>execution和storage是Spark Executor中内存的大户，other占用内存相对少很多，这里就不说了。在spark-1.6.0以前的版本，execution和storage的内存分配是固定的，使用的参数配置分别是spark.shuffle.memoryFraction（execution内存占Executor总内存大小，default 0.2）和spark.storage.memoryFraction（storage内存占Executor内存大小，default 0.6），因为是1.6.0以前这两块内存是互相隔离的，这就导致了Executor的内存利用率不高，而且需要根据Application的具体情况，使用者自己来调节这两个参数才能优化Spark的内存使用。在spark-1.6.0以上的版本，execution内存和storage内存可以相互借用，提高了内存的Spark中内存的使用率，同时也减少了OOM的情况。</p>
<p>在Spark-1.6.0后加入了堆外内存，进一步优化了Spark的内存使用，堆外内存使用JVM堆以外的内存，不会被gc回收，可以减少频繁的full gc，所以在Spark程序中，会长时间逗留再Spark程序中的大内存对象可以使用堆外内存存储。使用堆外内存有两种方式，一种是在rdd调用persist的时候传入参数StorageLevel.OFF_HEAP，这种使用方式需要配合Tachyon一起使用。另外一种是使用Spark自带的spark.memory.offHeap.enabled 配置为true进行使用，但是这种方式在1.6.0的版本还不支持使用，只是多了这个参数，在以后的版本中会开放。</p>
<p>OOM的问题通常出现在execution这块内存中，因为storage这块内存在存放数据满了之后，会直接丢弃内存中旧的数据，对性能有影响但是不会有OOM的问题。</p>
<h3 id="内存溢出解决方法："><a href="#内存溢出解决方法：" class="headerlink" title="内存溢出解决方法："></a>内存溢出解决方法：</h3><h3 id="1-map过程产生大量对象导致内存溢出："><a href="#1-map过程产生大量对象导致内存溢出：" class="headerlink" title="1. map过程产生大量对象导致内存溢出："></a>1. map过程产生大量对象导致内存溢出：</h3><p>这种溢出的原因是在单个map中产生了大量的对象导致的，例如：rdd.map(x&#x3D;&gt;for(i &lt;- 1 to 10000) yield i.toString)，这个操作在rdd中，每个对象都产生了10000个对象，这肯定很容易产生内存溢出的问题。针对这种问题，在不增加内存的情况下，可以通过减少每个Task的大小，以便达到每个Task即使产生大量的对象Executor的内存也能够装得下。具体做法可以在会产生大量对象的map操作之前调用repartition方法，分区成更小的块传入map。例如：rdd.repartition(10000).map(x&#x3D;&gt;for(i &lt;- 1 to 10000) yield i.toString)。<br>面对这种问题注意，不能使用rdd.coalesce方法，这个方法只能减少分区，不能增加分区，不会有shuffle的过程。</p>
<h3 id="2-数据不平衡导致内存溢出："><a href="#2-数据不平衡导致内存溢出：" class="headerlink" title="2.数据不平衡导致内存溢出："></a>2.数据不平衡导致内存溢出：</h3><p>数据不平衡除了有可能导致内存溢出外，也有可能导致性能的问题，解决方法和上面说的类似，就是调用repartition重新分区。这里就不再累赘了。</p>
<h3 id="3-coalesce调用导致内存溢出："><a href="#3-coalesce调用导致内存溢出：" class="headerlink" title="3.coalesce调用导致内存溢出："></a>3.coalesce调用导致内存溢出：</h3><p>这是我最近才遇到的一个问题，因为hdfs中不适合存小问题，所以Spark计算后如果产生的文件太小，我们会调用coalesce合并文件再存入hdfs中。但是这会导致一个问题，例如在coalesce之前有100个文件，这也意味着能够有100个Task，现在调用coalesce(10)，最后只产生10个文件，因为coalesce并不是shuffle操作，这意味着coalesce并不是按照我原本想的那样先执行100个Task，再将Task的执行结果合并成10个，而是从头到位只有10个Task在执行，原本100个文件是分开执行的，现在每个Task同时一次读取10个文件，使用的内存是原来的10倍，这导致了OOM。解决这个问题的方法是令程序按照我们想的先执行100个Task再将结果合并成10个文件，这个问题同样可以通过repartition解决，调用repartition(10)，因为这就有一个shuffle的过程，shuffle前后是两个Stage，一个100个分区，一个是10个分区，就能按照我们的想法执行。</p>
<h3 id="4-shuffle后内存溢出："><a href="#4-shuffle后内存溢出：" class="headerlink" title="4.shuffle后内存溢出："></a>4.shuffle后内存溢出：</h3><p>shuffle内存溢出的情况可以说都是shuffle后，单个文件过大导致的。在Spark中，join，reduceByKey这一类型的过程，都会有shuffle的过程，在shuffle的使用，需要传入一个partitioner，大部分Spark中的shuffle操作，默认的partitioner都是HashPatitioner，默认值是父RDD中最大的分区数,这个参数通过spark.default.parallelism控制(在spark-sql中用spark.sql.shuffle.partitions) ， spark.default.parallelism参数只对HashPartitioner有效，所以如果是别的Partitioner或者自己实现的Partitioner就不能使用spark.default.parallelism这个参数来控制shuffle的并发量了。如果是别的partitioner导致的shuffle内存溢出，就需要从partitioner的代码增加partitions的数量。</p>
<h3 id="5-standalone模式下资源分配不均匀导致内存溢出："><a href="#5-standalone模式下资源分配不均匀导致内存溢出：" class="headerlink" title="5.standalone模式下资源分配不均匀导致内存溢出："></a>5.standalone模式下资源分配不均匀导致内存溢出：</h3><p>在standalone的模式下如果配置了–total-executor-cores 和 –executor-memory 这两个参数，但是没有配置–executor-cores这个参数的话，就有可能导致，每个Executor的memory是一样的，但是cores的数量不同，那么在cores数量多的Executor中，由于能够同时执行多个Task，就容易导致内存溢出的情况。这种情况的解决方法就是同时配置–executor-cores或者spark.executor.cores参数，确保Executor资源分配均匀。</p>
<h3 id="6-在RDD中，共用对象能够减少OOM的情况："><a href="#6-在RDD中，共用对象能够减少OOM的情况：" class="headerlink" title="6.在RDD中，共用对象能够减少OOM的情况："></a>6.在RDD中，共用对象能够减少OOM的情况：</h3><p>这个比较特殊，这里说记录一下，遇到过一种情况，类似这样rdd.flatMap(x&#x3D;&gt;for(i &lt;- 1 to 1000) yield (“key”,”value”))导致OOM，但是在同样的情况下，使用rdd.flatMap(x&#x3D;&gt;for(i &lt;- 1 to 1000) yield “key”+”value”)就不会有OOM的问题，这是因为每次(“key”,”value”)都产生一个Tuple对象，而”key”+”value”，不管多少个，都只有一个对象，指向常量池。<br>(“key”,”value”)和(“key”,”value”)在内存中是存在不同位置的,也就是存了两份,但是”key”+”value”虽然出现了两次,但是只存了一份,在同一个地址,这用到了JVM常量池的知识.于是乎,如果RDD中有大量的重复数据,或者Array中需要存大量重复数据的时候我们都可以将重复数据转化为String,能够有效的减少内存使用.</p>
<h3 id="代码优化技巧："><a href="#代码优化技巧：" class="headerlink" title="代码优化技巧："></a>代码优化技巧：</h3><h3 id="1-使用mapPartitions代替大部分map操作，或者连续使用的map操作："><a href="#1-使用mapPartitions代替大部分map操作，或者连续使用的map操作：" class="headerlink" title="1.使用mapPartitions代替大部分map操作，或者连续使用的map操作："></a>1.使用mapPartitions代替大部分map操作，或者连续使用的map操作：</h3><p>这里需要稍微讲一下RDD和DataFrame的区别。RDD强调的是不可变对象，每个RDD都是不可变的，当调用RDD的map类型操作的时候，都是产生一个新的对象，这就导致了一个问题，如果对一个RDD调用大量的map类型操作的话，每个map操作会产生一个到多个RDD对象，这虽然不一定会导致内存溢出，但是会产生大量的中间数据，增加了gc操作。另外RDD在调用action操作的时候，会出发Stage的划分，但是在每个Stage内部可优化的部分是不会进行优化的，例如rdd.map(<em>+1).map(</em>+1)，这个操作在数值型RDD中是等价于rdd.map(_+2)的，但是RDD内部不会对这个过程进行优化。DataFrame则不同，DataFrame由于有类型信息所以是可变的，并且在可以使用sql的程序中，都有除了解释器外，都会有一个sql优化器，DataFrame也不例外，有一个优化器Catalyst，具体介绍看后面参考的文章。<br>上面说到的这些RDD的弊端，有一部分就可以使用mapPartitions进行优化，mapPartitions可以同时替代rdd.map,rdd.filter,rdd.flatMap的作用，所以在长操作中，可以在mapPartitons中将RDD大量的操作写在一起，避免产生大量的中间rdd对象，另外是mapPartitions在一个partition中可以复用可变类型，这也能够避免频繁的创建新对象。使用mapPartitions的弊端就是牺牲了代码的易读性。</p>
<h3 id="2-broadcast-join和普通join："><a href="#2-broadcast-join和普通join：" class="headerlink" title="2.broadcast join和普通join："></a>2.broadcast join和普通join：</h3><p>在大数据分布式系统中，大量数据的移动对性能的影响也是巨大的。基于这个思想，在两个RDD进行join操作的时候，如果其中一个RDD相对小很多，可以将小的RDD进行collect操作然后设置为broadcast变量，这样做之后，另一个RDD就可以使用map操作进行join，这样能够有效的减少相对大很多的那个RDD的数据移动。</p>
<h3 id="3-先filter在join："><a href="#3-先filter在join：" class="headerlink" title="3.先filter在join："></a>3.先filter在join：</h3><p>这个就是谓词下推，这个很显然，filter之后再join，shuffle的数据量会减少，这里提一点是spark-sql的优化器已经对这部分有优化了，不需要用户显示的操作，个人实现rdd的计算的时候需要注意这个。</p>
<h3 id="4-combineByKey的使用："><a href="#4-combineByKey的使用：" class="headerlink" title="4.combineByKey的使用："></a>4.combineByKey的使用：</h3><p>这个操作在Map-Reduce中也有，这里举个例子：rdd.groupByKey().mapValue(_.sum)比rdd.reduceByKey的效率低，原因有combineByKey的过程减少了shuffle的数据量，下面的没有。combineByKey是key-value型rdd自带的API，可以直接使用。</p>
<h3 id="5-在内存不足的使用，使用rdd-persist-StorageLevel-MEMORY-AND-DISK-SER-代替rdd-cache"><a href="#5-在内存不足的使用，使用rdd-persist-StorageLevel-MEMORY-AND-DISK-SER-代替rdd-cache" class="headerlink" title="5.在内存不足的使用，使用rdd.persist(StorageLevel.MEMORY_AND_DISK_SER)代替rdd.cache():"></a>5.在内存不足的使用，使用rdd.persist(StorageLevel.MEMORY_AND_DISK_SER)代替rdd.cache():</h3><p>rdd.cache()和rdd.persist(Storage.MEMORY_ONLY)是等价的，在内存不足的时候rdd.cache()的数据会丢失，再次使用的时候会重算，而rdd.persist(StorageLevel.MEMORY_AND_DISK_SER)在内存不足的时候会存储在磁盘，避免重算，只是消耗点IO时间。</p>
<h3 id="6-在spark使用hbase的时候，spark和hbase搭建在同一个集群："><a href="#6-在spark使用hbase的时候，spark和hbase搭建在同一个集群：" class="headerlink" title="6.在spark使用hbase的时候，spark和hbase搭建在同一个集群："></a>6.在spark使用hbase的时候，spark和hbase搭建在同一个集群：</h3><p>在spark结合hbase的使用中，spark和hbase最好搭建在同一个集群上上，或者spark的集群节点能够覆盖hbase的所有节点。hbase中的数据存储在HFile中，通常单个HFile都会比较大，另外Spark在读取Hbase的数据的时候，不是按照一个HFile对应一个RDD的分区，而是一个region对应一个RDD分区。所以在Spark读取Hbase的数据时，通常单个RDD都会比较大，如果不是搭建在同一个集群，数据移动会耗费很多的时间。</p>
<h3 id="参数优化部分："><a href="#参数优化部分：" class="headerlink" title="参数优化部分："></a>参数优化部分：</h3><h3 id="7-spark-driver-memory-default-1g-："><a href="#7-spark-driver-memory-default-1g-：" class="headerlink" title="7. spark.driver.memory (default 1g)："></a>7. spark.driver.memory (default 1g)：</h3><p>这个参数用来设置Driver的内存。在Spark程序中，SparkContext，DAGScheduler都是运行在Driver端的。对应rdd的Stage切分也是在Driver端运行，如果用户自己写的程序有过多的步骤，切分出过多的Stage，这部分信息消耗的是Driver的内存，这个时候就需要调大Driver的内存。</p>
<h3 id="8-spark-rdd-compress-default-false-："><a href="#8-spark-rdd-compress-default-false-：" class="headerlink" title="8. spark.rdd.compress (default false) ："></a>8. spark.rdd.compress (default false) ：</h3><p>这个参数在内存吃紧的时候，又需要persist数据有良好的性能，就可以设置这个参数为true，这样在使用persist(StorageLevel.MEMORY_ONLY_SER)的时候，就能够压缩内存中的rdd数据。减少内存消耗，就是在使用的时候会占用CPU的解压时间。</p>
<h3 id="9-spark-serializer-default-org-apache-spark-serializer-JavaSerializer"><a href="#9-spark-serializer-default-org-apache-spark-serializer-JavaSerializer" class="headerlink" title="9. spark.serializer (default org.apache.spark.serializer.JavaSerializer )"></a>9. spark.serializer (default org.apache.spark.serializer.JavaSerializer )</h3><p>建议设置为 org.apache.spark.serializer.KryoSerializer，因为KryoSerializer比JavaSerializer快，但是有可能会有些Object会序列化失败，这个时候就需要显示的对序列化失败的类进行KryoSerializer的注册，这个时候要配置spark.kryo.registrator参数或者使用参照如下代码：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(...).setAppName(...)</span><br><span class="line">conf.registerKryoClasses(<span class="type">Array</span>(classOf[<span class="type">MyClass1</span>],classOf[<span class="type">MyClass2</span>]))  </span><br><span class="line"><span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br></pre></td></tr></table></figure>
<h3 id="10-spark-memory-storageFraction-default-0-5"><a href="#10-spark-memory-storageFraction-default-0-5" class="headerlink" title="10.spark.memory.storageFraction (default 0.5)"></a>10.spark.memory.storageFraction (default 0.5)</h3><p>这个参数设置内存表示 Executor内存中 storage&#x2F;(storage+execution)，虽然spark-1.6.0+的版本内存storage和execution的内存已经是可以互相借用的了，但是借用和赎回也是需要消耗性能的，所以如果明知道程序中storage是多是少就可以调节一下这个参数。</p>
<h3 id="11-spark-locality-wait-default-3s-："><a href="#11-spark-locality-wait-default-3s-：" class="headerlink" title="11.spark.locality.wait (default 3s)："></a>11.spark.locality.wait (default 3s)：</h3><p>spark中有4中本地化执行level，PROCESS_LOCAL-&gt;NODE_LOCAL-&gt;RACK_LOCAL-&gt;ANY,一个task执行完，等待spark.locality.wait时间如果，第一次等待PROCESS的Task到达，如果没有，等待任务的等级下调到NODE再等待spark.locality.wait时间，依次类推，直到ANY。分布式系统是否能够很好的执行本地文件对性能的影响也是很大的。如果RDD的每个分区数据比较多，每个分区处理时间过长，就应该把 spark.locality.wait 适当调大一点，让Task能够有更多的时间等待本地数据。特别是在使用persist或者cache后，这两个操作过后，在本地机器调用内存中保存的数据效率会很高，但是如果需要跨机器传输内存中的数据，效率就会很低。</p>
<h3 id="12-spark-speculation-default-false"><a href="#12-spark-speculation-default-false" class="headerlink" title="12.spark.speculation (default false):"></a>12.spark.speculation (default false):</h3><p>一个大的集群中，每个节点的性能会有差异，spark.speculation这个参数表示空闲的资源节点会不会尝试执行还在运行，并且运行时间过长的Task，避免单个节点运行速度过慢导致整个任务卡在一个节点上。这个参数最好设置为true。与之相配合可以一起设置的参数有spark.speculation.×开头的参数。参考中有文章详细说明这个参数。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2021/06/11/Spark%E9%9D%A2%E5%AF%B9OOM%E9%97%AE%E9%A2%98%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95%E5%8F%8A%E4%BC%98%E5%8C%96%E6%80%BB%E7%BB%93/" data-id="cm1j2utfg0001b8ukgrl5dmoi" data-title="Spark面对OOM问题的解决方法及优化总结" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-index" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/05/21/index/" class="article-date">
  <time class="dt-published" datetime="2021-05-21T08:37:37.000Z" itemprop="datePublished">2021-05-21 16:37:37</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2021/05/21/index/">index</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>Welcome to <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a target="_blank" rel="noopener" href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a target="_blank" rel="noopener" href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a target="_blank" rel="noopener" href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2021/05/21/index/" data-id="cm1j2utfi0003b8uk14lrgd4o" data-title="index" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  


</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/08/">August 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/06/">June 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/05/">May 2021</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2023/08/18/JAVA%E5%A4%9A%E7%BA%BF%E7%A8%8B/">JAVA多线程</a>
          </li>
        
          <li>
            <a href="/2022/08/11/Kafka%E7%9B%B8%E5%85%B3%E5%91%BD%E4%BB%A4/">Kafka相关命令</a>
          </li>
        
          <li>
            <a href="/2022/08/10/kafka%E8%87%AA%E5%8A%A8%E5%88%9B%E5%BB%BATopic%E8%AE%BE%E7%BD%AE/">Partitions与Replication Factor调整准则</a>
          </li>
        
          <li>
            <a href="/2021/06/11/Spark%E9%9D%A2%E5%AF%B9OOM%E9%97%AE%E9%A2%98%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95%E5%8F%8A%E4%BC%98%E5%8C%96%E6%80%BB%E7%BB%93/">Spark面对OOM问题的解决方法及优化总结</a>
          </li>
        
          <li>
            <a href="/2021/05/21/index/">index</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2024 John Doe<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>